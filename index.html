<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Object Detection</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Raleway:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet">
</head>
<body>
    <div id="waiting">Waiting for the model...</div>
    <div id="mainFrame">
        <div id="camLiveDiv">
            <div id="videoMask">
                <video id="mainVideo" autoplay width="100%" height="100%"></video>
            </div>
        </div>  
        <div id="changeCam">Switch Cam</div>
    </div>

    <!-- Load TensorFlow.js. This is required to use coco-ssd model. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"> </script>
    <!-- Load the coco-ssd model. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"> </script>

    <script>
        const mainVideo = document.getElementById("mainVideo");
        const waiting = document.getElementById("waiting");
        const mainDivCam = document.getElementById("camLiveDiv");

        const changeCamEle = document.getElementById("changeCam");

        var model = undefined;

        var labels = [];
        var boxes = [];

        function predictWebCam() {
            model.detect(mainVideo).then(predictions => {
                for (let i = 0; i < labels.length; i++) {
                    mainDivCam.removeChild(labels[i]);
                }
                labels = [];
                for (let i = 0; i < boxes.length; i++) {
                    mainDivCam.removeChild(boxes[i]);
                }
                boxes = [];
                for (let i = 0; i < predictions.length; i++) {
                    if (predictions[i].score > 0.5) {
                        let newBox = document.createElement("div");

                        let scaleX = (mainVideo.getBoundingClientRect().width-60) / mainVideo.videoWidth;
                        let scaleY = (mainVideo.getBoundingClientRect().height-60) / mainVideo.videoHeight;
                        
                        let leftPos = predictions[i].bbox[0]*scaleX+30;
                        let topPos = predictions[i].bbox[1]*scaleY+30;
                        let widthDim = (predictions[i].bbox[2])*scaleX;
                        let heightDim = (predictions[i].bbox[3])*scaleY;

                        newBox.style = `
                        left: ${leftPos}px;
                        top: ${topPos}px; 
                        width: ${widthDim}px;
                        height: ${heightDim}px;
                        `
                        newBox.classList.add("box");
                        mainDivCam.appendChild(newBox);
                        boxes.push(newBox);


                        let lab = document.createElement("div");
                        lab.textContent = predictions[i].class + "  " + Math.round(predictions[i].score*100, 2) + "%";
                        lab.style = `
                        left: ${leftPos}px;
                        top: ${topPos}px; 
                        width: ${widthDim}px;
                        `
                        lab.classList.add("label");
                        mainDivCam.appendChild(lab);
                        labels.push(lab);
                    }
                }
            });
            window.requestAnimationFrame(predictWebCam);
        }

        var camFacingMode = "user";

        function loadVideo(cam) {
            if (navigator.mediaDevices.getUserMedia) {
                navigator.mediaDevices.getUserMedia({ video: {facingMode: cam}})
                .then(stream => {
                    mainVideo.srcObject = stream;
                    mainVideo.addEventListener("loadeddata", predictWebCam)
                }).catch(err => {
                    console.log(err);
                });
            }
            else {
                console.log("Video not supported!");
            }
        }

        cocoSsd.load().then(loadedModel => {
            model = loadedModel;
            mainVideo.style.display = "block";
            waiting.style.display = "none";
            changeCamEle.style.display = "block";
            changeCamEle.addEventListener("click", changeCam);
            loadVideo(camFacingMode);
        })

        function changeCam() {
            mainVideo.srcObject.getTracks().forEach((track) => {
                track.stop();
            })
            if (camFacingMode == "user") {
                camFacingMode = "environment";
            }
            else if (camFacingMode == "environment"){
                camFacingMode = "user";

            }
            loadVideo(camFacingMode);
        }



    </script>
</body>
</html>